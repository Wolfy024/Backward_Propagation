# Backward_Propagation
An implementation of Backward Propagation with Numpy from scratch.


Achieves 84 % on MNIST with 2 Linear Layers with 10 neurons each.
Made purely with numpy and maths.
